<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Kafka-Consumer | Mr.Li's blog</title><meta name="author" content="CHLi"><meta name="copyright" content="CHLi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="消费方式pullconsumer采用从broker中主动拉取数据。 Kafka采用这种方式。 注：pull模式不足之处是，如果Kafka没有数 据，消费者可能会陷入循环中，一直返回 空数据。 pushKafka没有采用这种方式，因为由broker 决定消息发送速率，很难适应所有消费者的 消费速率。 工作原理总体流程 消费者组原理Consumer Group（CG）：消费者组，由多个 consume">
<meta property="og:type" content="article">
<meta property="og:title" content="Kafka-Consumer">
<meta property="og:url" content="http://example.com/2024/04/12/Kafka-Consumer/index.html">
<meta property="og:site_name" content="Mr.Li&#39;s blog">
<meta property="og:description" content="消费方式pullconsumer采用从broker中主动拉取数据。 Kafka采用这种方式。 注：pull模式不足之处是，如果Kafka没有数 据，消费者可能会陷入循环中，一直返回 空数据。 pushKafka没有采用这种方式，因为由broker 决定消息发送速率，很难适应所有消费者的 消费速率。 工作原理总体流程 消费者组原理Consumer Group（CG）：消费者组，由多个 consume">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.JPG">
<meta property="article:published_time" content="2024-04-12T07:58:19.000Z">
<meta property="article:modified_time" content="2024-06-29T09:39:53.662Z">
<meta property="article:author" content="CHLi">
<meta property="article:tag" content="Kafka">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.JPG"><link rel="shortcut icon" href="/img/spaceshuttle.png"><link rel="canonical" href="http://example.com/2024/04/12/Kafka-Consumer/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Kafka-Consumer',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-29 17:39:53'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">76</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/topGraph.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Mr.Li's blog"><span class="site-name">Mr.Li's blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> Categories</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Kafka-Consumer</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-04-12T07:58:19.000Z" title="发表于 2024-04-12 15:58:19">2024-04-12</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-29T09:39:53.662Z" title="更新于 2024-06-29 17:39:53">2024-06-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Kafka/">Kafka</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Kafka-Consumer"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="消费方式"><a href="#消费方式" class="headerlink" title="消费方式"></a>消费方式</h1><h2 id="pull"><a href="#pull" class="headerlink" title="pull"></a>pull</h2><p>consumer采用从broker中主动拉取数据。 Kafka采用这种方式。</p>
<p><strong>注</strong>：pull模式不足之处是，如果Kafka没有数 据，消费者可能会陷入循环中，一直返回 空数据。</p>
<h2 id="push"><a href="#push" class="headerlink" title="push"></a>push</h2><p>Kafka没有采用这种方式，因为由broker 决定消息发送速率，很难适应所有消费者的 消费速率。</p>
<h1 id="工作原理"><a href="#工作原理" class="headerlink" title="工作原理"></a>工作原理</h1><h2 id="总体流程"><a href="#总体流程" class="headerlink" title="总体流程"></a>总体流程</h2><p><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412143106.png" alt="image.png"></p>
<h2 id="消费者组原理"><a href="#消费者组原理" class="headerlink" title="消费者组原理"></a>消费者组原理</h2><p>Consumer Group（CG）：消费者组，由多个 consumer 组成。形成一个消费者组的条件，是所有消费者的 groupid 相同。</p>
<ul>
<li>消费者组内每个消费者负责消费不同分区的数据，<strong>一个分区只能由一个组内消费者消费</strong>。</li>
<li>消费者组之间互不影响。所有的消费者都属于某个消费者组，即消费者组是逻辑上的一个订阅者。<br><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412150522.png" alt="image.png"></li>
</ul>
<p><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412150556.png" alt="image.png"></p>
<h3 id="消费者组初始化流程"><a href="#消费者组初始化流程" class="headerlink" title="消费者组初始化流程"></a>消费者组初始化流程</h3><ol>
<li>确定 coordinator：辅助实现消费者组的初始化和分区分配。coordinator 的节点选择=groupid 的 hashcode 值%50。</li>
<li>coordinator 选出一个 consumer Leader。</li>
<li>coordinator 需要把消费的 topic 情况发送给 leader 消费者</li>
<li>consumer leader 制定消费方案（即每个 consumer 需要消费的分区规划），并发送给 coordinator</li>
<li>coordinator 将消费方案发送给每个 consumer</li>
<li>每个 consumer 开始消费数据，并与 coordinator 保持心跳。一旦超时（默认是 45 s），该消费者就会被移除，并出发再平衡机制。或者消费者处理消息的时间过长（5 分钟）也会触发再平衡</li>
</ol>
<h3 id="消费者组消费详细流程"><a href="#消费者组消费详细流程" class="headerlink" title="消费者组消费详细流程"></a>消费者组消费详细流程</h3><p><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412152535.png" alt="image.png"></p>
<ol>
<li>消费者组中消费者向 ConsumerNetworkClient 发送请求，ConsumerNetworkClient 向需要消费的 broker 分区的 leader 发送请求</li>
<li>对应 broker 分区的 leader 向 completedFetches（双端队列） 发送数据，得到的数据经过反序列化，拦截器，处理数据</li>
<li>消费者从 completedFetches 中 poll 数据。<h3 id="面试问题：当有一个消费者想要加入消费者组时，流程是什么？"><a href="#面试问题：当有一个消费者想要加入消费者组时，流程是什么？" class="headerlink" title="面试问题：当有一个消费者想要加入消费者组时，流程是什么？"></a>面试问题：当有一个消费者想要加入消费者组时，流程是什么？</h3></li>
</ol>
<p>在 Apache Kafka 中，当一个消费者组中加入新的消费者时，主要经历以下几个步骤：</p>
<ol>
<li><p><strong>消费者加入消费者组</strong>：<br>新的消费者启动并向 Kafka 集群中的协调器（通常是一个 broker）发送加入组的请求。这个请求会包括消费者组的标识符和消费者自身的信息。</p>
</li>
<li><p><strong>重新平衡（Rebalance）</strong>：<br>当新消费者加入消费者组时，或者现有消费者退出消费者组时，协调器会触发一个重新平衡的过程。重新平衡的目的是为了重新分配消费者组内的分区所有权，以确保所有的消费者都有分区可以消费。</p>
</li>
<li><p><strong>分区再分配</strong>：<br>在重新平衡过程中，协调器会根据分区分配策略（如 Range, RoundRobin, Sticky 等）重新分配分区给消费者组中的每个消费者。分配策略可以影响分区的分布，例如：</p>
<ul>
<li><strong>Range</strong>：将主题的分区范围尽可能均等地分配给每个消费者。</li>
<li><strong>RoundRobin</strong>：依次轮流将分区分配给每个消费者。</li>
<li><strong>Sticky</strong>：尽量保持原有消费者的分区不变，只对新消费者或必要时进行调整。</li>
</ul>
</li>
<li><p><strong>同步分区数据</strong>：<br>分区重新分配完成后，每个消费者会从协调器接收到它应该消费的分区列表。消费者只能消费指定的分区。</p>
</li>
<li><p><strong>开始消费消息</strong>：<br>一旦分区分配完成，每个消费者开始从其分配的分区中读取数据。如果是新的消费者或分区迁移后，消费者可能会从上一个消费者停止的地方开始消费，这通常是通过检查分区的 offset 来实现。</p>
</li>
<li><p><strong>处理完毕</strong>：<br>重新平衡完成后，消费者组中的所有消费者将继续消费其各自分区的消息。</p>
</li>
</ol>
<p>重新平衡是一个必要的过程，它确保了 Kafka 中消息消费的负载均衡和高可用性。当然，重新平衡过程也可能导致短暂的消费停顿，因为在重新平衡期间，消费者可能不能读取或消费任何消息。为了尽量减少这种影响，开发者需要仔细选择合适的分区分配策略和优化消费者组的配置。</p>
<h3 id="消费者重要参数"><a href="#消费者重要参数" class="headerlink" title="消费者重要参数"></a>消费者重要参数</h3><h4 id="bootstrap-servers"><a href="#bootstrap-servers" class="headerlink" title="bootstrap.servers"></a>bootstrap.servers</h4><p>向Kafka集群建立初始连接用到的host/port列表。</p>
<h4 id="key-deserializer-和-value-deserializer"><a href="#key-deserializer-和-value-deserializer" class="headerlink" title="key.deserializer 和 value.deserializer"></a>key.deserializer 和 value.deserializer</h4><p>指定接收消息的 key 和 value 的反序列化类型。一定要写全类名。</p>
<h4 id="group-id"><a href="#group-id" class="headerlink" title="group.id"></a>group.id</h4><p>标记消费者所属的消费者组。</p>
<h4 id="enable-auto-commit"><a href="#enable-auto-commit" class="headerlink" title="enable.auto.commit"></a>enable.auto.commit</h4><p>默认值为 true，消费者会自动周期性地向服务器提交偏移 量。</p>
<h4 id="auto-commit-interval-ms"><a href="#auto-commit-interval-ms" class="headerlink" title="auto.commit.interval.ms"></a>auto.commit.interval.ms</h4><p>如果设置了 enable.auto.commit 的值为 true， 则该值定义了 消费者偏移量向Kafka提交的频率，默认5s。</p>
<h4 id="auto-offset-reset"><a href="#auto-offset-reset" class="headerlink" title="auto.offset.reset"></a>auto.offset.reset</h4><p>当Kafka 中没有初始偏移量或当前偏移量在服务器中不存在 （如，数据被删除了），该如何处理？ earliest：自动重置偏 移量到最早的偏移量。 latest：默认，自动重置偏移量为最 新的偏移量。 none：如果消费组原来的（previous）偏移量 不存在，则向消费者抛异常。 anything：向消费者抛异常。</p>
<h4 id="offsets-topic-num-partitions"><a href="#offsets-topic-num-partitions" class="headerlink" title="offsets.topic.num.partitions"></a>offsets.topic.num.partitions</h4><p>_consumer_offsets 的分区数，默认是 50个分区。</p>
<h4 id="heartbeat-interval-ms"><a href="#heartbeat-interval-ms" class="headerlink" title="heartbeat.interval.ms"></a>heartbeat.interval.ms</h4><p>Kafka 消费者和coordinator之间的心跳时间，默认3s。 该条目的值必须小于 session.timeout.ms ，也不应该高于 session.timeout.ms 的 1/3。</p>
<h4 id="session-timeout-ms"><a href="#session-timeout-ms" class="headerlink" title="session.timeout.ms"></a>session.timeout.ms</h4><p>Kafka 消费者和 coordinator 之间连接超时时间，默认 45s。 超过该值，该消费者被移除，消费者组执行再平衡。</p>
<h4 id="max-poll-interval-ms"><a href="#max-poll-interval-ms" class="headerlink" title="max.poll.interval.ms"></a>max.poll.interval.ms</h4><p>消费者处理消息的最大时长，默认是5分钟。超过该值，该 消费者被移除，消费者组执行再平衡。</p>
<h4 id="fetch-min-bytes"><a href="#fetch-min-bytes" class="headerlink" title="fetch.min.bytes"></a>fetch.min.bytes</h4><p>默认1个字节。消费者获取服务器端一批消息最小的字节 数。</p>
<h4 id="fetch-max-wait-ms"><a href="#fetch-max-wait-ms" class="headerlink" title="fetch.max.wait.ms"></a>fetch.max.wait.ms</h4><p>默认500ms。如果没有从服务器端获取到一批数据的最小字 节数。该时间到，仍然会返回数据。</p>
<h4 id="fetch-max-bytes"><a href="#fetch-max-bytes" class="headerlink" title="fetch.max.bytes"></a>fetch.max.bytes</h4><p>默认Default: 52428800（50 m）。消费者获取服务器端一批 消息最大的字节数。如果服务器端一批次的数据大于该值 （50m）仍然可以拉取回来这批数据，因此，这不是一个绝 对最大值。一批次的大小受message.max.bytes （broker config）or max.message.bytes （topic config）影响。</p>
<h4 id="max-poll-records"><a href="#max-poll-records" class="headerlink" title="max.poll.records"></a>max.poll.records</h4><p>一次poll拉取数据返回消息的最大条数，默认是500条。</p>
<h2 id="再分配策略"><a href="#再分配策略" class="headerlink" title="再分配策略"></a>再分配策略</h2><h3 id="Range-再分配策略"><a href="#Range-再分配策略" class="headerlink" title="Range 再分配策略"></a>Range 再分配策略</h3><p>Range 是对每个 topic 而言的。</p>
<p><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412154340.png" alt="image.png"></p>
<ol>
<li>首先对<strong>同一个 topic 里面的分区按照序号进行排序</strong>，并对消费者按照字母顺序进行排序。 </li>
<li>假如现在有 7 个分区，3 个消费者，排序后的分区将会 是 0,1,2,3,4,5,6；消费者排序完之后将会是 C 0, C 1, C 2。 通过 partitions 数/consumer 数 来决定每个消费者应该 消费几个分区。如果除不尽，那么前面几个消费者将会多 消费 1 个分区。 </li>
<li>例如，7/3 = 2 余 1 ，除不尽，那么消费者 C 0 便会多 消费 1 个分区。8/3=2 余 2，除不尽，那么 C 0 和 C 1 分别多 消费一个。 broker-1 Partition-1 broker-2 Partition-2 broker-3 注意：如果只是针对 1 个 topic 而言，C 0 消费者多消费 1 个分区影响不是很大。但是如果有 N 多个 topic，那么针对每 个 topic，消费者 C 0 都将多消费 1 个分区，topic 越多，C 0 消 费的分区会比其他消费者明显多消费 N 个分区。<br><strong>注</strong>：容易产生数据倾斜。</li>
</ol>
<h4 id="Range分区分配再平衡案例"><a href="#Range分区分配再平衡案例" class="headerlink" title="Range分区分配再平衡案例"></a>Range分区分配再平衡案例</h4><ol>
<li><p>停止掉 0 号消费者，快速重新发送消息观看结果（45 s 以内，越快越好）。<br>1 号消费者：消费到 3、4 号分区数据。<br>2 号消费者：消费到 5、6 号分区数据。<br>0 号消费者的任务会整体被分配到 1 号消费者或者 2 号消费者。<br><strong>注</strong>：0号消费者挂掉后，消费者组需要按照超时时间45s 来判断它是否退出，所以需 要等待，时间到了45s 后，判断它真的退出就会把任务分配给其他 broker 执行。 </p>
</li>
<li><p>再次重新发送消息观看结果（45 s 以后）。<br>1 号消费者：消费到 0、1、2、3 号分区数据。<br>2 号消费者：消费到 4、5、6 号分区数据。<br><strong>注</strong>：消费者 0 已经被踢出消费者组，所以重新按照 range 方式分配。</p>
<h3 id="RoundRobin-以及再平衡"><a href="#RoundRobin-以及再平衡" class="headerlink" title="RoundRobin 以及再平衡"></a>RoundRobin 以及再平衡</h3></li>
</ol>
<p>RoundRobin 针对集群中所有Topic而言。</p>
<p>RoundRobin 轮询分区策略，是把所有的 partition 和所有的 consumer 都列出来，然后按照hashcode进行排序，最后 通过轮询算法来分配partition 给到各个消费者。</p>
<p><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412154540.png" alt="image.png"></p>
<h4 id="RoundRobin分区分配再平衡案例"><a href="#RoundRobin分区分配再平衡案例" class="headerlink" title="RoundRobin分区分配再平衡案例"></a>RoundRobin分区分配再平衡案例</h4><ol>
<li>停止掉 0 号消费者，快速重新发送消息观看结果（45 s 以内，越快越好）。<br>1 号消费者：消费到 2、5 号分区数据<br>2 号消费者：消费到 4、1 号分区数据<br>0 号消费者的任务会按照 RoundRobin 的方式，把数据轮询分成 0 、6 和 3 号分区数据， 分别由 1 号消费者或者 2 号消费者消费。<br><strong>注</strong>：0 号消费者挂掉后，消费者组需要按照超时时间 45 s 来判断它是否退出，所以需要等待，时间到了 45 s 后，判断它真的退出就会把任务分配给其他 broker 执行。 </li>
<li>再次重新发送消息观看结果（45 s 以后）。<br>1 号消费者：消费到 0、2、4、6 号分区数据<br>2 号消费者：消费到 1、3、5 号分区数据。<h3 id="Sticky-以及再平衡"><a href="#Sticky-以及再平衡" class="headerlink" title="Sticky 以及再平衡"></a>Sticky 以及再平衡</h3></li>
</ol>
<p>粘性分区定义：可以理解为分配的结果带有“粘性的”。即在执行一次新的分配之前， 考虑上一次分配的结果，尽量少的调整分配的变动，可以节省大量的开销。</p>
<p>粘性分区是 Kafka 从 0.11.x 版本开始引入这种分配策略，<strong>首先会尽量均衡的放置分区 到消费者上面</strong>，在出现同一消费者组内消费者出现问题的时候，会<strong>尽量保持原有分配的分区不变化</strong>。</p>
<h4 id="Sticky分区分配再平衡案例"><a href="#Sticky分区分配再平衡案例" class="headerlink" title="Sticky分区分配再平衡案例"></a>Sticky分区分配再平衡案例</h4><ol>
<li>停止掉 0 号消费者，快速重新发送消息观看结果（45 s 以内，越快越好）。<br>1 号消费者：消费到 2、5、3 号分区数据。<br>2 号消费者：消费到 4、6 号分区数据。<br>0 号消费者的任务会按照粘性规则，尽可能均衡的随机分成 0 和 1 号分区数据，分别 由 1 号消费者或者 2 号消费者消费。<br><strong>注</strong>：0 号消费者挂掉后，消费者组需要按照超时时间 45 s 来判断它是否退出，所以需 要等待，时间到了 45 s 后，判断它真的退出就会把任务分配给其他 broker 执行。 </li>
<li>再次重新发送消息观看结果（45 s 以后）。<br>1 号消费者：消费到 2、3、5 号分区数据。<br>2 号消费者：消费到 0、1、4、6 号分区数据。<br><strong>注</strong>：消费者 0 已经被踢出消费者组，所以重新按照粘性方式分配。</li>
</ol>
<h2 id="Offset-位移"><a href="#Offset-位移" class="headerlink" title="Offset 位移"></a>Offset 位移</h2><p><img src="https://cdn.jsdelivr.net/gh/MLiLay/img/img20240412155515.png" alt="image.png"></p>
<h3 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h3><p>在 Apache Kafka 中，消费者的 offset 起着非常关键的作用，主要包括以下几个方面：</p>
<ol>
<li><p><strong>消息追踪</strong>：<br>Offset 是 Kafka 中每条消息在日志中的位置标识。每个消息在其对应的分区中都有一个唯一的连续增长的序号，即 offset。消费者通过维护每个分区的最新消费 offset 来追踪自己已经消费到哪个位置，从而确保消息可以按顺序被处理。</p>
</li>
<li><p><strong>故障恢复</strong>：<br>当消费者因故障停止后重启，或者在发生消费者组重新平衡后，消费者可以通过记录的 offset 重新定位到上次消费的位置，继续消费未处理的消息。这确保了消息的持续消费不受中断，并且可以避免消息的重复消费。</p>
</li>
<li><p><strong>确保消息不丢失</strong>：<br>消费者在处理完消息后更新其 offset。通过可靠地存储这些 offset（通常存储在 Kafka 或外部系统中），即使在发生系统崩溃的情况下，也能保证消息不会丢失，因为消费者可以从上次已确认的 offset 重新开始消费。</p>
</li>
<li><p><strong>支持消息重放</strong>：<br>如果需要，消费者可以调整其 offset 来重新消费某些消息。这在系统测试或者数据出现问题需要重新处理时非常有用。</p>
</li>
<li><p><strong>支持多个消费者实例</strong>：<br>在一个消费者组中，多个消费者实例可以共同消费一个主题的不同分区。每个消费者维护自己负责的分区的 offset，使得消息的分布式处理成为可能，从而提高了消费的并行度和效率。</p>
</li>
<li><p><strong>精细控制消费过程</strong>：<br>开发者可以基于 offset 实现更精细的消费控制，比如实现某些高级特性，包括跳过某些不需要的消息、定位到特定的消息进行处理等。</p>
</li>
</ol>
<h1 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h1><h2 id="单个消费者"><a href="#单个消费者" class="headerlink" title="单个消费者"></a>单个消费者</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.time.Duration; </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList; </span><br><span class="line"><span class="keyword">import</span> java.util.Arrays; </span><br><span class="line"><span class="keyword">import</span> java.util.Properties; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerPartition</span> &#123; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123; </span><br><span class="line"> </span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>(); </span><br><span class="line"> </span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,<span class="string">&quot;hadoop102:9092&quot;</span>); </span><br><span class="line">		<span class="comment">// 配置序列化 必须 </span></span><br><span class="line">		properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); </span><br><span class="line">        </span><br><span class="line">		properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 配置消费者组（必须），名字可以任意起 </span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG,<span class="string">&quot;test&quot;</span>); </span><br><span class="line"> </span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> </span><br><span class="line">		<span class="title class_">KafkaConsumer</span>&lt;&gt;(properties); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 消费某个主题的某个分区数据 </span></span><br><span class="line">        ArrayList&lt;TopicPartition&gt; topicPartitions = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(); </span><br><span class="line">        topicPartitions.add(<span class="keyword">new</span> <span class="title class_">TopicPartition</span>(<span class="string">&quot;first&quot;</span>, <span class="number">0</span>)); </span><br><span class="line">        kafkaConsumer.assign(topicPartitions); </span><br><span class="line"> </span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>)&#123; </span><br><span class="line"> </span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); </span><br><span class="line"> </span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123; </span><br><span class="line">                System.out.println(consumerRecord); </span><br><span class="line">            &#125; </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2 id="消费者组"><a href="#消费者组" class="headerlink" title="消费者组"></a>消费者组</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.time.Duration; </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList; </span><br><span class="line"><span class="keyword">import</span> java.util.Properties; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumer1</span> &#123; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123; </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 1.创建消费者的配置对象 </span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>(); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 2.给消费者配置对象添加参数 </span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 配置序列化 必须 </span></span><br><span class="line">        </span><br><span class="line">		properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, </span><br><span class="line">		StringDeserializer.class.getName()); </span><br><span class="line">        </span><br><span class="line">		properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, </span><br><span class="line">		StringDeserializer.class.getName()); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 配置消费者组 必须 </span></span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test&quot;</span>); </span><br><span class="line">		<span class="comment">// 创建消费者对象 </span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;String, String&gt;(properties); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 注册主题 </span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(); </span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>); </span><br><span class="line">        kafkaConsumer.subscribe(topics); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 拉取数据打印 </span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123; </span><br><span class="line">            <span class="comment">// 设置1s中消费一批数据 </span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); </span><br><span class="line"> </span><br><span class="line">            <span class="comment">// 打印消费到的数据 </span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123; </span><br><span class="line">                System.out.println(consumerRecord); </span><br><span class="line">            &#125; </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2 id="指定-offset-位置消费"><a href="#指定-offset-位置消费" class="headerlink" title="指定 offset 位置消费"></a>指定 offset 位置消费</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerConfig; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecord; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.ConsumerRecords; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.KafkaConsumer; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.time.Duration; </span><br><span class="line"><span class="keyword">import</span> java.util.ArrayList; </span><br><span class="line"><span class="keyword">import</span> java.util.HashSet; </span><br><span class="line"><span class="keyword">import</span> java.util.Properties; </span><br><span class="line"><span class="keyword">import</span> java.util.Set; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerSeek</span> &#123; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123; </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 0  配置信息 </span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>(); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 连接 </span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// key value反序列化 </span></span><br><span class="line">        </span><br><span class="line">		properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); </span><br><span class="line">        </span><br><span class="line">		properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); </span><br><span class="line"> </span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test2&quot;</span>); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 1 创建一个消费者 </span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties); </span><br><span class="line">		<span class="comment">// 2 订阅一个主题 </span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(); </span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>); </span><br><span class="line">        kafkaConsumer.subscribe(topics); </span><br><span class="line"> </span><br><span class="line">        Set&lt;TopicPartition&gt; assignment= <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(); </span><br><span class="line"> </span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123; </span><br><span class="line">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); </span><br><span class="line">            <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费） </span></span><br><span class="line">            assignment = kafkaConsumer.assignment(); </span><br><span class="line">        &#125; </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 遍历所有分区，并指定offset从1700的位置开始消费 </span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition tp: assignment) &#123; </span><br><span class="line">            kafkaConsumer.seek(tp, <span class="number">1700</span>); </span><br><span class="line">        &#125; </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 3 消费该主题数据 </span></span><br><span class="line">        <span class="keyword">while</span> (<span class="literal">true</span>) &#123; </span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); </span><br><span class="line"> </span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123; </span><br><span class="line">                System.out.println(consumerRecord); </span><br><span class="line">            &#125; </span><br><span class="line">        &#125; </span><br><span class="line">    &#125; </span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>
<h2 id="指定消费时间消费"><a href="#指定消费时间消费" class="headerlink" title="指定消费时间消费"></a>指定消费时间消费</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.kafka.clients.consumer.*; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.TopicPartition; </span><br><span class="line"><span class="keyword">import</span> org.apache.kafka.common.serialization.StringDeserializer; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">import</span> java.time.Duration; </span><br><span class="line"><span class="keyword">import</span> java.util.*; </span><br><span class="line"> </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">CustomConsumerForTime</span> &#123; </span><br><span class="line"> </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123; </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 0  配置信息</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">properties</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>(); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 连接 </span></span><br><span class="line">        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, <span class="string">&quot;hadoop102:9092&quot;</span>); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// key value反序列化 </span></span><br><span class="line">        </span><br><span class="line">	properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); </span><br><span class="line">        </span><br><span class="line">	properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); </span><br><span class="line"> </span><br><span class="line">        properties.put(ConsumerConfig.GROUP_ID_CONFIG, <span class="string">&quot;test2&quot;</span>); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 1 创建一个消费者 </span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(properties); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 2 订阅一个主题 </span></span><br><span class="line">        ArrayList&lt;String&gt; topics = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;&gt;(); </span><br><span class="line">        topics.add(<span class="string">&quot;first&quot;</span>); </span><br><span class="line">        kafkaConsumer.subscribe(topics); </span><br><span class="line"> </span><br><span class="line">        Set&lt;TopicPartition&gt; assignment = <span class="keyword">new</span> <span class="title class_">HashSet</span>&lt;&gt;(); </span><br><span class="line"> </span><br><span class="line">        <span class="keyword">while</span> (assignment.size() == <span class="number">0</span>) &#123; </span><br><span class="line">            kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); </span><br><span class="line">            <span class="comment">// 获取消费者分区分配信息（有了分区分配信息才能开始消费） </span></span><br><span class="line">            assignment = kafkaConsumer.assignment(); </span><br><span class="line">        &#125; </span><br><span class="line"> </span><br><span class="line">        HashMap&lt;TopicPartition, Long&gt; timestampToSearch = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;(); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 封装集合存储，每个分区对应一天前的数据 </span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123; </span><br><span class="line">            timestampToSearch.put(topicPartition, System.currentTimeMillis() - <span class="number">1</span> * <span class="number">24</span> * <span class="number">3600</span> * <span class="number">1000</span>); </span><br><span class="line">        &#125; </span><br><span class="line">        <span class="comment">// 获取从1天前开始消费的每个分区的offset </span></span><br><span class="line">        Map&lt;TopicPartition, OffsetAndTimestamp&gt; offsets = kafkaConsumer.offsetsForTimes(timestampToSearch); </span><br><span class="line"> </span><br><span class="line">        <span class="comment">// 遍历每个分区，对每个分区设置消费时间。 </span></span><br><span class="line">        <span class="keyword">for</span> (TopicPartition topicPartition : assignment) &#123; </span><br><span class="line">            <span class="type">OffsetAndTimestamp</span> <span class="variable">offsetAndTimestamp</span> <span class="operator">=</span> offsets.get(topicPartition); </span><br><span class="line"> </span><br><span class="line">            <span class="comment">// 根据时间指定开始消费的位置 </span></span><br><span class="line">            <span class="keyword">if</span> (offsetAndTimestamp != <span class="literal">null</span>)&#123; </span><br><span class="line">                kafkaConsumer.seek(topicPartition, offsetAndTimestamp.offset()); </span><br><span class="line">            &#125; </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 3 消费该主题数据 </span></span><br><span class="line">		<span class="keyword">while</span> (<span class="literal">true</span>) &#123; </span><br><span class="line">			ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">1</span>)); </span><br><span class="line">			<span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123; </span><br><span class="line">				System.out.println(consumerRecord); </span><br><span class="line">			&#125; </span><br><span class="line">		&#125; </span><br><span class="line">	&#125; </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Kafka/">Kafka</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/04/14/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90-ABTest-%E4%B8%A4%E7%A7%8D%E9%94%99%E8%AF%AF/" title="数据分析-ABTest-两种错误"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">数据分析-ABTest-两种错误</div></div></a></div><div class="next-post pull-right"><a href="/2024/04/06/MySQL-%E6%97%A5%E5%BF%97/" title="MySQL-日志"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">MySQL-日志</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/04/21/Kafka-Broker/" title="Kafka-Broker"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-04-21</div><div class="title">Kafka-Broker</div></div></a></div><div><a href="/2024/03/25/Kafka-Producer/" title="Kafka-Producer"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-25</div><div class="title">Kafka-Producer</div></div></a></div><div><a href="/2024/03/24/Kafka-%E4%B8%8E%E5%85%B6%E4%BB%96%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%9A%84%E5%8C%BA%E5%88%AB/" title="Kafka-与其他消息队列区别"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-24</div><div class="title">Kafka-与其他消息队列区别</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CHLi</div><div class="author-info__description">Welcome to Mr.Li's blog</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">76</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/MLiLay"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome! This is MLiLay's Blog.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E6%96%B9%E5%BC%8F"><span class="toc-number">1.</span> <span class="toc-text">消费方式</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#pull"><span class="toc-number">1.1.</span> <span class="toc-text">pull</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#push"><span class="toc-number">1.2.</span> <span class="toc-text">push</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86"><span class="toc-number">2.</span> <span class="toc-text">工作原理</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%80%BB%E4%BD%93%E6%B5%81%E7%A8%8B"><span class="toc-number">2.1.</span> <span class="toc-text">总体流程</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%8E%9F%E7%90%86"><span class="toc-number">2.2.</span> <span class="toc-text">消费者组原理</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E5%88%9D%E5%A7%8B%E5%8C%96%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.1.</span> <span class="toc-text">消费者组初始化流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%B6%88%E8%B4%B9%E8%AF%A6%E7%BB%86%E6%B5%81%E7%A8%8B"><span class="toc-number">2.2.2.</span> <span class="toc-text">消费者组消费详细流程</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%9D%A2%E8%AF%95%E9%97%AE%E9%A2%98%EF%BC%9A%E5%BD%93%E6%9C%89%E4%B8%80%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85%E6%83%B3%E8%A6%81%E5%8A%A0%E5%85%A5%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84%E6%97%B6%EF%BC%8C%E6%B5%81%E7%A8%8B%E6%98%AF%E4%BB%80%E4%B9%88%EF%BC%9F"><span class="toc-number">2.2.3.</span> <span class="toc-text">面试问题：当有一个消费者想要加入消费者组时，流程是什么？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E9%87%8D%E8%A6%81%E5%8F%82%E6%95%B0"><span class="toc-number">2.2.4.</span> <span class="toc-text">消费者重要参数</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#bootstrap-servers"><span class="toc-number">2.2.4.1.</span> <span class="toc-text">bootstrap.servers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#key-deserializer-%E5%92%8C-value-deserializer"><span class="toc-number">2.2.4.2.</span> <span class="toc-text">key.deserializer 和 value.deserializer</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#group-id"><span class="toc-number">2.2.4.3.</span> <span class="toc-text">group.id</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#enable-auto-commit"><span class="toc-number">2.2.4.4.</span> <span class="toc-text">enable.auto.commit</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#auto-commit-interval-ms"><span class="toc-number">2.2.4.5.</span> <span class="toc-text">auto.commit.interval.ms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#auto-offset-reset"><span class="toc-number">2.2.4.6.</span> <span class="toc-text">auto.offset.reset</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#offsets-topic-num-partitions"><span class="toc-number">2.2.4.7.</span> <span class="toc-text">offsets.topic.num.partitions</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#heartbeat-interval-ms"><span class="toc-number">2.2.4.8.</span> <span class="toc-text">heartbeat.interval.ms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#session-timeout-ms"><span class="toc-number">2.2.4.9.</span> <span class="toc-text">session.timeout.ms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#max-poll-interval-ms"><span class="toc-number">2.2.4.10.</span> <span class="toc-text">max.poll.interval.ms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fetch-min-bytes"><span class="toc-number">2.2.4.11.</span> <span class="toc-text">fetch.min.bytes</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fetch-max-wait-ms"><span class="toc-number">2.2.4.12.</span> <span class="toc-text">fetch.max.wait.ms</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#fetch-max-bytes"><span class="toc-number">2.2.4.13.</span> <span class="toc-text">fetch.max.bytes</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#max-poll-records"><span class="toc-number">2.2.4.14.</span> <span class="toc-text">max.poll.records</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%86%8D%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">2.3.</span> <span class="toc-text">再分配策略</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#Range-%E5%86%8D%E5%88%86%E9%85%8D%E7%AD%96%E7%95%A5"><span class="toc-number">2.3.1.</span> <span class="toc-text">Range 再分配策略</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Range%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E5%86%8D%E5%B9%B3%E8%A1%A1%E6%A1%88%E4%BE%8B"><span class="toc-number">2.3.1.1.</span> <span class="toc-text">Range分区分配再平衡案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#RoundRobin-%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">2.3.2.</span> <span class="toc-text">RoundRobin 以及再平衡</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#RoundRobin%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E5%86%8D%E5%B9%B3%E8%A1%A1%E6%A1%88%E4%BE%8B"><span class="toc-number">2.3.2.1.</span> <span class="toc-text">RoundRobin分区分配再平衡案例</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Sticky-%E4%BB%A5%E5%8F%8A%E5%86%8D%E5%B9%B3%E8%A1%A1"><span class="toc-number">2.3.3.</span> <span class="toc-text">Sticky 以及再平衡</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Sticky%E5%88%86%E5%8C%BA%E5%88%86%E9%85%8D%E5%86%8D%E5%B9%B3%E8%A1%A1%E6%A1%88%E4%BE%8B"><span class="toc-number">2.3.3.1.</span> <span class="toc-text">Sticky分区分配再平衡案例</span></a></li></ol></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Offset-%E4%BD%8D%E7%A7%BB"><span class="toc-number">2.4.</span> <span class="toc-text">Offset 位移</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BD%9C%E7%94%A8"><span class="toc-number">2.4.1.</span> <span class="toc-text">作用</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.</span> <span class="toc-text">示例</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8D%95%E4%B8%AA%E6%B6%88%E8%B4%B9%E8%80%85"><span class="toc-number">3.1.</span> <span class="toc-text">单个消费者</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B6%88%E8%B4%B9%E8%80%85%E7%BB%84"><span class="toc-number">3.2.</span> <span class="toc-text">消费者组</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A-offset-%E4%BD%8D%E7%BD%AE%E6%B6%88%E8%B4%B9"><span class="toc-number">3.3.</span> <span class="toc-text">指定 offset 位置消费</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%8C%87%E5%AE%9A%E6%B6%88%E8%B4%B9%E6%97%B6%E9%97%B4%E6%B6%88%E8%B4%B9"><span class="toc-number">3.4.</span> <span class="toc-text">指定消费时间消费</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/22/Spark-%E6%BA%90%E7%A0%81-persist%E4%B8%8Echeckpoint/" title="Spark-源码-persist与checkpoint">Spark-源码-persist与checkpoint</a><time datetime="2024-07-22T09:02:52.238Z" title="发表于 2024-07-22 17:02:52">2024-07-22</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/11/Celeborn/" title="Celeborn">Celeborn</a><time datetime="2024-07-11T12:46:48.425Z" title="发表于 2024-07-11 20:46:48">2024-07-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/11/Spark-%E6%BA%90%E7%A0%81-Broadcast/" title="Spark-源码-Broadcast">Spark-源码-Broadcast</a><time datetime="2024-07-11T12:29:06.531Z" title="发表于 2024-07-11 20:29:06">2024-07-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/01/Spark-%E6%BA%90%E7%A0%81-%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/" title="Spark-源码-任务提交流程（Yarn）">Spark-源码-任务提交流程（Yarn）</a><time datetime="2024-07-01T13:56:32.213Z" title="发表于 2024-07-01 21:56:32">2024-07-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/18/NIO%E4%B8%8E%E9%9B%B6%E6%8B%B7%E8%B4%9D/" title="NIO-NIO与零拷贝">NIO-NIO与零拷贝</a><time datetime="2024-05-18T06:57:04.000Z" title="发表于 2024-05-18 14:57:04">2024-05-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By CHLi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>