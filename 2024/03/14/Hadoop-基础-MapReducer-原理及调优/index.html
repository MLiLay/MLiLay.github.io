<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>Hadoop-MapReduce-原理及调优 | Mr.Li's blog</title><meta name="author" content="CHLi"><meta name="copyright" content="CHLi"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="框架 MapReducer 书主要可以分成五块，分别是在 MapTask 段的 Input（InputFormat），Mapper ，中间的 Shuffle 部分，还有 ReduceTask 端端 Reducer 和 Output（OutputFormat）。 Input 端InputFormat切片与并行运算机制数据块：Block 是 HDFS 物理上把数据分成一块一块。数据块是 HDFS 存储">
<meta property="og:type" content="article">
<meta property="og:title" content="Hadoop-MapReduce-原理及调优">
<meta property="og:url" content="http://example.com/2024/03/14/Hadoop-%E5%9F%BA%E7%A1%80-MapReducer-%E5%8E%9F%E7%90%86%E5%8F%8A%E8%B0%83%E4%BC%98/index.html">
<meta property="og:site_name" content="Mr.Li&#39;s blog">
<meta property="og:description" content="框架 MapReducer 书主要可以分成五块，分别是在 MapTask 段的 Input（InputFormat），Mapper ，中间的 Shuffle 部分，还有 ReduceTask 端端 Reducer 和 Output（OutputFormat）。 Input 端InputFormat切片与并行运算机制数据块：Block 是 HDFS 物理上把数据分成一块一块。数据块是 HDFS 存储">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/avatar.JPG">
<meta property="article:published_time" content="2024-03-14T10:52:30.346Z">
<meta property="article:modified_time" content="2024-06-29T10:10:01.689Z">
<meta property="article:author" content="CHLi">
<meta property="article:tag" content="Hadoop">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/avatar.JPG"><link rel="shortcut icon" href="/img/spaceshuttle.png"><link rel="canonical" href="http://example.com/2024/03/14/Hadoop-%E5%9F%BA%E7%A1%80-MapReducer-%E5%8E%9F%E7%90%86%E5%8F%8A%E8%B0%83%E4%BC%98/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=4.13.0"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: undefined,
  noticeOutdate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.11.1/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'Hadoop-MapReduce-原理及调优',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2024-06-29 18:10:01'
}</script><script>(win=>{
      win.saveToLocal = {
        set: (key, value, ttl) => {
          if (ttl === 0) return
          const now = Date.now()
          const expiry = now + ttl * 86400000
          const item = {
            value,
            expiry
          }
          localStorage.setItem(key, JSON.stringify(item))
        },
      
        get: key => {
          const itemStr = localStorage.getItem(key)
      
          if (!itemStr) {
            return undefined
          }
          const item = JSON.parse(itemStr)
          const now = Date.now()
      
          if (now > item.expiry) {
            localStorage.removeItem(key)
            return undefined
          }
          return item.value
        }
      }
    
      win.getScript = (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        script.onerror = reject
        script.onload = script.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          script.onload = script.onreadystatechange = null
          resolve()
        }

        Object.keys(attr).forEach(key => {
          script.setAttribute(key, attr[key])
        })

        document.head.appendChild(script)
      })
    
      win.getCSS = (url, id = false) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onerror = reject
        link.onload = link.onreadystatechange = function() {
          const loadState = this.readyState
          if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
          link.onload = link.onreadystatechange = null
          resolve()
        }
        document.head.appendChild(link)
      })
    
      win.activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
        if (t === 'dark') activateDarkMode()
        else if (t === 'light') activateLightMode()
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
      const detectApple = () => {
        if(/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
          document.documentElement.classList.add('apple')
        }
      }
      detectApple()
    })(window)</script><meta name="generator" content="Hexo 7.2.0"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/avatar.JPG" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="sidebar-site-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">76</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><hr class="custom-hr"/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/topGraph.jpg')"><nav id="nav"><span id="blog-info"><a href="/" title="Mr.Li's blog"><span class="site-name">Mr.Li's blog</span></a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> Archives</span></a></div></div><div id="toggle-menu"><a class="site-page" href="javascript:void(0);"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Hadoop-MapReduce-原理及调优</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2024-03-14T10:52:30.346Z" title="发表于 2024-03-14 18:52:30">2024-03-14</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2024-06-29T10:10:01.689Z" title="更新于 2024-06-29 18:10:01">2024-06-29</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/Hadoop/">Hadoop</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title="Hadoop-MapReduce-原理及调优"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="框架"><a href="#框架" class="headerlink" title="框架"></a>框架</h1><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240131141309.png" alt="image.png"></p>
<p>MapReducer 书主要可以分成五块，分别是在 MapTask 段的 Input（InputFormat），Mapper ，中间的 Shuffle 部分，还有 ReduceTask 端端 Reducer 和 Output（OutputFormat）。</p>
<h1 id="Input-端"><a href="#Input-端" class="headerlink" title="Input 端"></a>Input 端</h1><h2 id="InputFormat"><a href="#InputFormat" class="headerlink" title="InputFormat"></a>InputFormat</h2><h3 id="切片与并行运算机制"><a href="#切片与并行运算机制" class="headerlink" title="切片与并行运算机制"></a>切片与并行运算机制</h3><p>数据块：Block 是 HDFS <strong>物理上</strong>把数据分成一块一块。<strong>数据块是 HDFS 存储数据单位</strong>。</p>
<p>数据切片：数据切片只是在<strong>逻辑上</strong>对输入进行分片，并不会在磁盘上将其切分成片进行存储。 数据切片是MapReduce 程序计算输入数据的单位，一个切片会对应启动一个MapTask。</p>
<p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240131142007.png" alt="image.png"></p>
<p>就像图中如果切片大小是 100，那么对于 DataNode 创建的 MapTask 就要跨 Node 进行任务，这显然是不合理的，所以在默认情况下切片大小会等于 Block 大小，从而保证 MapTask 不会跨 Node 进行任务。</p>
<p>还有需要注意的是切片的时候是对每一个文件单独进行切片的，并不是拼接所有数据后切片。</p>
<h3 id="Job-提交任务与切片源码详解"><a href="#Job-提交任务与切片源码详解" class="headerlink" title="Job 提交任务与切片源码详解"></a>Job 提交任务与切片源码详解</h3><h4 id="Job-提交任务源码"><a href="#Job-提交任务源码" class="headerlink" title="Job 提交任务源码"></a>Job 提交任务源码</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line">waitForCompletion()</span><br><span class="line"></span><br><span class="line">submit();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1建立连接</span></span><br><span class="line"></span><br><span class="line">connect();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1）创建提交 Job的代理</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">new</span> <span class="title class_">Cluster</span>(getConfiguration());</span><br><span class="line"></span><br><span class="line"><span class="comment">// （1）判断是本地运行环境还是 yarn集群运行环境</span></span><br><span class="line"></span><br><span class="line">initialize(jobTrackAddr, conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2 提交 job</span></span><br><span class="line"></span><br><span class="line">submitter.submitJobInternal(Job.<span class="built_in">this</span>, cluster)</span><br><span class="line"></span><br><span class="line"><span class="comment">// 1）创建给集群提交数据的 Stag路径</span></span><br><span class="line"></span><br><span class="line"><span class="type">Path</span> <span class="variable">jobStagingArea</span> <span class="operator">=</span> JobSubmissionFiles.getStagingDir(cluster, conf);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 2）获取 jobid ，并创建 Job路径</span></span><br><span class="line"></span><br><span class="line"><span class="type">JobID</span> <span class="variable">jobId</span> <span class="operator">=</span> submitClient.getNewJobID();</span><br><span class="line"></span><br><span class="line"><span class="comment">// 3）拷贝 jar包到集群</span></span><br><span class="line"></span><br><span class="line">copyAndConfigureFiles(job, submitJobDir);</span><br><span class="line"></span><br><span class="line">rUploader.uploadFiles(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 4）计算切片，生成切片规划文件</span></span><br><span class="line"></span><br><span class="line">writeSplits(job, submitJobDir);</span><br><span class="line"></span><br><span class="line">maps = writeNewSplits(job, jobSubmitDir);</span><br><span class="line"></span><br><span class="line">input.getSplits(job);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 5）向 Stag路径写 XML配置文件</span></span><br><span class="line"></span><br><span class="line">writeConf(conf, submitJobFile);</span><br><span class="line"></span><br><span class="line">conf.writeXml(out);</span><br><span class="line"></span><br><span class="line"><span class="comment">// 6）提交 Job,返回提交状态</span></span><br><span class="line"></span><br><span class="line">status = submitClient.submitJob(jobId, submitJobDir.toString(),</span><br></pre></td></tr></table></figure>
<p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240131142439.png" alt="image.png"></p>
<p>流程大致如下：</p>
<ul>
<li>Submit（）方法提交</li>
<li>Connect（）方法，判断是连接集群（yarn）还是 Local（本地）</li>
<li>创建数据 job 对应的路径，主要由 staging 和 jobid 组成，提交集群就在 hdfs 上创建，本地就本地</li>
<li>调用 FileInputFormat. getSplits（）获取切片规划，并序列化成文件，并上传 HDFS 或保存本地</li>
<li>将 Job 参数写到文件 Job. xml 中，并上传或保存本地</li>
<li>如果是集群允许还需要将 jar 包上传 HDFS</li>
</ul>
<h3 id="FileInputFormat切片源码解析"><a href="#FileInputFormat切片源码解析" class="headerlink" title="FileInputFormat切片源码解析"></a>FileInputFormat切片源码解析</h3><p>切片的源码在 FileInputFormat 中的 getSplits（）方法</p>
<p>大致的流程如下</p>
<ol>
<li>程序先找到你数据存储的目录。</li>
<li>开始遍历处理（规划切片）目录下的每一个文件，这里导致了是对每一个文件单独切片</li>
<li>遍历第一个文件 ss. txt。<ul>
<li>获取文件大小 fs.sizeOf (ss. txt)</li>
<li>计算切片大小，写篇大小公式为：<strong>computeSplitSize (Math.max (minSize,Math.min (maxSize, blocksize)))</strong>=blocksize=128 M 这里的带下是可以调节的，其中 minSize 和 maxSize 是可以别调节的，调节 minSize 就能放大，minSize 默认为 1，maxSize 默认为 LongWritable. MAX_VALUE</li>
<li>默认情况下，切片大小=blocksize</li>
<li>开始切，形成第 1 个切片：ss. txt—0:128 M 第 2 个切片 ss. txt—128:256 M 第 3 个切片 ss. txt—256 M: 300 M.<strong>注：每次切片时，都要判断切完剩下的部分是否大于块的 1.1 倍，不大于 1.1 倍就划分一块切片</strong></li>
<li>将切片信息写到一个切片规划文件中</li>
<li>整个切片的核心过程在 getSplit ()方法中完成</li>
<li><strong>InputSplit</strong>只记录了切片的元数据信息，比如起始位置、长度以及所在的节点列表等。</li>
</ul>
</li>
<li>提交切片规划文件（里面包含的只是切片的信息并没有实际对物理文件进行切片）到 YARN 上，YARN 上的 MrAppMaster 就可以根据切片规划文件计算开启 MapTask 个数。</li>
</ol>
<h3 id="TextInputFormat"><a href="#TextInputFormat" class="headerlink" title="TextInputFormat"></a>TextInputFormat</h3><p>TextInputFormat 是默认的 FileInputFormat 实现类，也就是不规定的时候默认读取文件是使用 TextInputFormat 来按行对单个文件进行读取。</p>
<h3 id="CombineTextInputFormat"><a href="#CombineTextInputFormat" class="headerlink" title="CombineTextInputFormat"></a>CombineTextInputFormat</h3><p>是 FileInputFormat 实现类。</p>
<h4 id="应用场景"><a href="#应用场景" class="headerlink" title="应用场景"></a>应用场景</h4><p>CombineTextInputFormat 用于<strong>小文件过多的场景</strong>，它可以将多个小文件从逻辑上规划到</p>
<p>一个切片中，这样，多个小文件就可以交给一个 MapTask 处理。当然，如果超出了设置的最大切片大小，也会有多个切片，自然也会有多个 MapTask。</p>
<h4 id="虚拟存储切片最大值设置"><a href="#虚拟存储切片最大值设置" class="headerlink" title="虚拟存储切片最大值设置"></a>虚拟存储切片最大值设置</h4><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">CombineTextInputFormat.setMaxInputSplitSize(job, <span class="number">4194304</span>);<span class="comment">// 4m</span></span><br></pre></td></tr></table></figure>
<p><strong>注意</strong>：虚拟存储切片最大值设置最好根据实际的小文件大小情况来设置具体的值。</p>
<h4 id="切片机制"><a href="#切片机制" class="headerlink" title="切片机制"></a>切片机制</h4><p>生成切片过程包括：<strong>虚拟存储过程</strong>和<strong>切片过程</strong>二部分。</p>
<p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240131161801.png" alt="image.png"></p>
<h5 id="虚拟存储过程"><a href="#虚拟存储过程" class="headerlink" title="虚拟存储过程"></a>虚拟存储过程</h5><p>将输入目录下所有文件大小，依次和设置的 setMaxInputSplitSize 值比较，如果不</p>
<p>大于设置的最大值，逻辑上划分一个块。如果输入文件大于设置的最大值且大于两倍，</p>
<p>那么以最大值切割一块；<strong>当剩余数据大小超过设置的最大值且不大于最大值2 倍，此时</strong></p>
<p><strong>将文件均分成 2 个虚拟存储块（防止出现太小切片）</strong>。</p>
<h5 id="切片过程"><a href="#切片过程" class="headerlink" title="切片过程"></a>切片过程</h5><ol>
<li><p>判断虚拟存储的文件大小是否大于 setMaxInputSplitSize 值，大于等于则单独形成一个切片。</p>
</li>
<li><p>如果不大于则跟下一个虚拟存储文件进行合并，共同形成一个切片。</p>
</li>
</ol>
<h1 id="MapReduce-工作原理（Shuffle）"><a href="#MapReduce-工作原理（Shuffle）" class="headerlink" title="MapReduce 工作原理（Shuffle）"></a>MapReduce 工作原理（Shuffle）</h1><h2 id="Input-Map-shuffle"><a href="#Input-Map-shuffle" class="headerlink" title="Input + Map + shuffle"></a>Input + Map + shuffle</h2><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202135956.png" alt="image.png"></p>
<p>前面 Input 客户端的部分省略，客户端后的部分（Map+Shuffle）：</p>
<ol>
<li>MapTask 按照使用 InputFormat 的实现类的方式从文件中读数据</li>
<li>Map 操作后，outputCollector 收集存入一个环形的内存缓冲区（缓冲区一半存元信息一半存数据），<strong>元数据内包含分区信息</strong>。</li>
<li>当缓冲区存方的数据到达<strong>一定的阈值时（溢出）</strong>，从剩余空间的中间位置方向存储（为了并行一边溢出一遍存）。</li>
<li>在溢出前每个不同的分区数据进行排序（<strong>快排</strong>），排序完成后溢出到文件中（分区内有序），一次完整的任务溢出的数据可能会有很多个。</li>
<li>因为溢出的文件会有很多个所以需要对溢出保存的数据进行按照分区合并并排序（归并排序）</li>
</ol>
<p><strong>注</strong>：缓冲区的大小默认数 100M，但是可以通过修改参数：mapreduce.task.io.sort.mb 进行调节。</p>
<h2 id="Reduce"><a href="#Reduce" class="headerlink" title="Reduce"></a>Reduce</h2><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202140909.png" alt="image.png"></p>
<ol>
<li>从每个 ReduceTask（负责不同的分区数据）磁盘中<strong>按照分区拉取数据（主动）</strong>，不同的 MapTask 会产生多个文件，所以需要对数据进行合并并排序（归并排序）。</li>
<li>从前往后读取区 key，将相同 Key 对键值对分为同一组不断传递给 Reducer。</li>
<li>Reducer 处理好的数据按照不同 OutputFormat 实现类的方式传递给 RecordWriter 写入文件。</li>
</ol>
<h2 id="Shuffle-机制详解"><a href="#Shuffle-机制详解" class="headerlink" title="Shuffle 机制详解"></a>Shuffle 机制详解</h2><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202141622.png" alt="image.png"></p>
<p>与上面的步骤类似，只是更详细一些。</p>
<ol>
<li>一个 MapTask 对环形缓冲区进行写入（元信息：idx，分区，keystart，vstart，数据）</li>
<li>缓冲区到达阈值（80%）后反向写入，同时开始溢出</li>
<li>溢出前数据按照分区进行分区内排序（快排）</li>
<li>数据在溢出前还可以使用 combiner 进行提前的 reduce（不能影响最后的结果）</li>
<li>多个溢出文件需按照分区进行合并并排序（归并排序），合并后也可以选择 combiner</li>
<li>合并后就可以按照分区写入磁盘，写入前可以进行压缩</li>
</ol>
<h2 id="Partition"><a href="#Partition" class="headerlink" title="Partition"></a>Partition</h2><p>Partition 就是前面提到的分区，有多少个分区就会有多少个ReduceTask</p>
<p><strong>注</strong>：和前面的切片区分开，<strong>切片决定 MapTask 数，Partition 决定 ReduceTask 数，ReduceTask 数量就会决定产生结果文件的数量</strong>。</p>
<h3 id="默认分区"><a href="#默认分区" class="headerlink" title="默认分区"></a>默认分区</h3><p>默认分区是根据 key 的 hashCode 对 ReduceTasks 个数取模得到的。用户没法控制哪个</p>
<p>key存储到哪个分区。</p>
<p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202152923.png" alt="image.png"></p>
<h3 id="自定义分区"><a href="#自定义分区" class="headerlink" title="自定义分区"></a>自定义分区</h3><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202152948.png" alt="image.png"></p>
<p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202153122.png" alt="image.png"></p>
<p>当 ReduceTask 设置为 1 的时候，在源码里面根本就不会管多少个分区，直接就是 1 个。</p>
<h3 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h3><p>Mapper</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.partitioner;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text, FlowBean&gt; &#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">outK</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//1 获取一行数据,转成字符串  </span></span><br><span class="line">        <span class="type">String</span> <span class="variable">line</span> <span class="operator">=</span> value.toString();  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//2 切割数据  </span></span><br><span class="line">        String[] split = line.split(<span class="string">&quot;\t&quot;</span>);  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//3 抓取我们需要的数据:手机号,上行流量,下行流量  </span></span><br><span class="line">        <span class="type">String</span> <span class="variable">phone</span> <span class="operator">=</span> split[<span class="number">1</span>];  </span><br><span class="line">        <span class="type">String</span> <span class="variable">up</span> <span class="operator">=</span> split[split.length - <span class="number">3</span>];  </span><br><span class="line">        <span class="type">String</span> <span class="variable">down</span> <span class="operator">=</span> split[split.length - <span class="number">2</span>];  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//4 封装outK outV  </span></span><br><span class="line">        outK.set(phone);  </span><br><span class="line">        outV.setUpFlow(Long.parseLong(up));  </span><br><span class="line">        outV.setDownFlow(Long.parseLong(down));  </span><br><span class="line">        outV.setSumFlow();  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//5 写出outK outV  </span></span><br><span class="line">        context.write(outK, outV);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Reducer<br><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.partitioner;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowReducer</span> <span class="keyword">extends</span> <span class="title class_">Reducer</span>&lt;Text, FlowBean, Text, FlowBean&gt; &#123;  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">FlowBean</span> <span class="variable">outV</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">FlowBean</span>();  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">reduce</span><span class="params">(Text key, Iterable&lt;FlowBean&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException &#123;  </span><br><span class="line">  </span><br><span class="line">        <span class="type">long</span> <span class="variable">totalUp</span> <span class="operator">=</span> <span class="number">0</span>;  </span><br><span class="line">        <span class="type">long</span> <span class="variable">totalDown</span> <span class="operator">=</span> <span class="number">0</span>;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//1 遍历values,将其中的上行流量,下行流量分别累加  </span></span><br><span class="line">        <span class="keyword">for</span> (FlowBean flowBean : values) &#123;  </span><br><span class="line">            totalUp += flowBean.getUpFlow();  </span><br><span class="line">            totalDown += flowBean.getDownFlow();  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//2 封装outKV  </span></span><br><span class="line">        outV.setUpFlow(totalUp);  </span><br><span class="line">        outV.setDownFlow(totalDown);  </span><br><span class="line">        outV.setSumFlow();  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//3 写出outK outV  </span></span><br><span class="line">        context.write(key,outV);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>Driver</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.partitioner;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowDriver</span> &#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException, ClassNotFoundException, InterruptedException &#123;  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//1 获取job对象  </span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();  </span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//2 关联本Driver类  </span></span><br><span class="line">        job.setJarByClass(FlowDriver.class);  </span><br><span class="line">  </span><br><span class="line">        <span class="comment">//3 关联Mapper和Reducer  </span></span><br><span class="line">        job.setMapperClass(FlowMapper.class);  </span><br><span class="line">        job.setReducerClass(FlowReducer.class);  </span><br><span class="line">  </span><br><span class="line"><span class="comment">//4 设置Map端输出KV类型  </span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);  </span><br><span class="line">        job.setMapOutputValueClass(FlowBean.class);  </span><br><span class="line">  </span><br><span class="line"><span class="comment">//5 设置程序最终输出的KV类型  </span></span><br><span class="line">        job.setOutputKeyClass(Text.class);  </span><br><span class="line">        job.setOutputValueClass(FlowBean.class);  </span><br><span class="line">        <span class="comment">//8 指定自定义分区器  </span></span><br><span class="line">        job.setPartitionerClass(ProvincePartitioner.class);  </span><br><span class="line"><span class="comment">//9 同时指定相应数量的 ReduceTask        job.setNumReduceTasks(5);  </span></span><br><span class="line">  </span><br><span class="line"><span class="comment">//6 设置程序的输入输出路径  </span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/Users/mrli/work/bigdata/LearningFile/input/inputflow&quot;</span>));  </span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/Users/mrli/work/bigdata/LearningFile/output/flowoutput&quot;</span>));  </span><br><span class="line">  </span><br><span class="line"><span class="comment">//7 提交Job  </span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);  </span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>FlowBean</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.partitioner;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Writable;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;  </span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line">  </span><br><span class="line"><span class="comment">//1 继承Writable接口  </span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">Writable</span> &#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> upFlow; <span class="comment">//上行流量  </span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> downFlow; <span class="comment">//下行流量  </span></span><br><span class="line">    <span class="keyword">private</span> <span class="type">long</span> sumFlow; <span class="comment">//总流量  </span></span><br><span class="line">  </span><br><span class="line">    <span class="comment">//2 提供无参构造  </span></span><br><span class="line">    <span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//3 提供三个参数的getter和setter方法  </span></span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> upFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.upFlow = upFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getDownFlow</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> downFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setDownFlow</span><span class="params">(<span class="type">long</span> downFlow)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.downFlow = downFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getSumFlow</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> sumFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">(<span class="type">long</span> sumFlow)</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.sumFlow = sumFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSumFlow</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="built_in">this</span>.sumFlow = <span class="built_in">this</span>.upFlow + <span class="built_in">this</span>.downFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//4 实现序列化和反序列化方法,注意顺序一定要保持一致  </span></span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">write</span><span class="params">(DataOutput dataOutput)</span> <span class="keyword">throws</span> IOException &#123;  </span><br><span class="line">        dataOutput.writeLong(upFlow);  </span><br><span class="line">        dataOutput.writeLong(downFlow);  </span><br><span class="line">        dataOutput.writeLong(sumFlow);  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">readFields</span><span class="params">(DataInput dataInput)</span> <span class="keyword">throws</span> IOException &#123;  </span><br><span class="line">        <span class="built_in">this</span>.upFlow = dataInput.readLong();  </span><br><span class="line">        <span class="built_in">this</span>.downFlow = dataInput.readLong();  </span><br><span class="line">        <span class="built_in">this</span>.sumFlow = dataInput.readLong();  </span><br><span class="line">    &#125;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//5 重写ToString  </span></span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">public</span> String <span class="title function_">toString</span><span class="params">()</span> &#123;  </span><br><span class="line">        <span class="keyword">return</span> upFlow + <span class="string">&quot;\t&quot;</span> + downFlow + <span class="string">&quot;\t&quot;</span> + sumFlow;  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Partition</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.partitioner;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Partitioner;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">ProvincePartitioner</span> <span class="keyword">extends</span> <span class="title class_">Partitioner</span>&lt;Text, FlowBean&gt; &#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getPartition</span><span class="params">(Text text, FlowBean flowBean, <span class="type">int</span> numPartitions)</span> &#123;  </span><br><span class="line">        <span class="type">String</span> <span class="variable">prePhone</span> <span class="operator">=</span> text.toString().substring(<span class="number">0</span>, <span class="number">3</span>);  </span><br><span class="line">        <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> <span class="number">0</span>;  </span><br><span class="line">        <span class="keyword">if</span> (prePhone.equals(<span class="string">&quot;136&quot;</span>))  </span><br><span class="line">            partition = <span class="number">0</span>;  </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (prePhone.equals(<span class="string">&quot;137&quot;</span>))  </span><br><span class="line">            partition = <span class="number">1</span>;  </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (prePhone.equals(<span class="string">&quot;138&quot;</span>))  </span><br><span class="line">            partition = <span class="number">2</span>;  </span><br><span class="line">        <span class="keyword">else</span> <span class="keyword">if</span> (prePhone.equals(<span class="string">&quot;139&quot;</span>))  </span><br><span class="line">            partition = <span class="number">3</span>;  </span><br><span class="line">        <span class="keyword">else</span> partition = <span class="number">0</span>;  </span><br><span class="line">        <span class="keyword">return</span> partition;  </span><br><span class="line">    &#125;  </span><br></pre></td></tr></table></figure>
<h2 id="WritableComparable-自定义排序顺序"><a href="#WritableComparable-自定义排序顺序" class="headerlink" title="WritableComparable (自定义排序顺序)"></a>WritableComparable (自定义排序顺序)</h2><p>默认的排序是对 Key 进行排序，排序的规则是根据字典顺序。</p>
<p>如果需要按照特定的规则进行排序，需要排序的属性包含在 key 中，使自定义的类实现 WritableComparable&lt;&gt;接口中的 compareTo 方法即可</p>
<h3 id="示例-1"><a href="#示例-1" class="headerlink" title="示例"></a>示例</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.WritableComparable;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataInput;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.DataOutput;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> java.io.IOException;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">FlowBean</span> <span class="keyword">implements</span> <span class="title class_">WritableComparable</span>&lt;FlowBean&gt; &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">long</span> upFlow; <span class="comment">//上行流量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">long</span> downFlow; <span class="comment">//下行流量</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">private</span> <span class="type">long</span> sumFlow; <span class="comment">//总流量</span></span><br><span class="line"></span><br><span class="line"><span class="comment">//提供无参构造</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="title function_">FlowBean</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">//生成三个属性的 getter和 setter方法</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="type">long</span> <span class="title function_">getUpFlow</span><span class="params">()</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> upFlow;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setUpFlow</span><span class="params">(<span class="type">long</span> upFlow)</span> &#123;</span><br><span class="line"></span><br><span class="line"><span class="built_in">this</span>.upFlow = upFlow;</span><br><span class="line"></span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h2 id="Combiner"><a href="#Combiner" class="headerlink" title="Combiner"></a>Combiner</h2><p>Combiner 某种意义上其实就是Reducer</p>
<p>所以构造的方法其实也就是继承 Reducer，然后将 Driver 中的对应设置即可</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">job.setCombinerClass(MyCombiner.class);</span><br></pre></td></tr></table></figure>
<p>当然也可以用现成的 Reducer 作为Combiner</p>
<h2 id="MapReduce-内核源码解析"><a href="#MapReduce-内核源码解析" class="headerlink" title="MapReduce 内核源码解析"></a>MapReduce 内核源码解析</h2><h3 id="MapTask"><a href="#MapTask" class="headerlink" title="MapTask"></a>MapTask</h3><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202161536.png" alt="image.png"></p>
<ol>
<li>Read 阶段：MapTask 通过 InputFormat 获得的 RecordReader，从输入 InputSplit 中解析出一个个 key/value。</li>
<li>Map 阶段：该节点主要是将解析出的 key/value 交给用户编写 map ()函数处理，并产生一系列新的 key/value。</li>
<li>ollect 收集阶段：在用户编写 map ()函数中，当数据处理完成后，一般会调用 OutputCollector.collect ()输出结果。在该函数内部，它会将生成的 key/value 分区（调用 Partitioner），并写入一个环形内存缓冲区中。</li>
<li>Spill 阶段：即“溢写”，当环形缓冲区满后， MapReduce 会将数据写到本地磁盘上，生成一个临时文件。需要注意的是，将数据写入本地磁盘之前，先要对数据进行一次本地排序，并在必要时对数据进行合并、压缩等操作。溢写阶段详情：步骤 1：利用快速排序算法对缓存区内的数据进行排序，排序方式是，先按照分区编号 Partition 进行排序，然后按照 key 进行排序。这样，经过排序后，数据以分区为单位聚集在一起，且同一分区内所有数据按照 key 有序。步骤 2：按照分区编号由小到大依次将每个分区中的数据写入任务工作目录下的临时文件 output/spillN. out（N 表示当前溢写次数）中。如果用户设置了 Combiner，则写入文件之前，对每个分区中的数据进行一次聚集操作。步骤 3：将分区数据的元信息写到内存索引数据结构 SpillRecord 中，其中每个分区的元信息包括在临时文件中的偏移量、压缩前数据大小和压缩后数据大小。如果当前内存索引大小超过 1 MB，则将内存索引写到文件 output/spillN. out. index 中。</li>
<li>Merge 阶段：当所有数据处理完成后，MapTask 对所有临时文件进行一次合并，以确保最终只会生成一个数据文件。当所有数据处理完后，MapTask 会将所有临时文件合并成一个大文件，并保存到文件 output/file. out 中，同时生成相应的索引文件 output/file. out. index。在进行文件合并过程中，MapTask 以分区为单位进行合并。对于某个分区，它将采用多轮递归合并的方式。每轮合并 mapreduce. task. io. sort. factor （默认 10）个文件，并将产生的文件重新加入待合并列表中，对文件排序后，重复以上过程，直到最终得到一个大文件。让每个 MapTask 最终只生成一个数据文件，可避免同时打开大量文件和同时读取大量小文件产生的随机读取带来的开销。</li>
</ol>
<h4 id="源码解析流程"><a href="#源码解析流程" class="headerlink" title="源码解析流程"></a>源码解析流程</h4><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202162035.png" alt="image.png"></p>
<h3 id="ReduceTask"><a href="#ReduceTask" class="headerlink" title="ReduceTask"></a>ReduceTask</h3><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202162056.png" alt="image.png"></p>
<ol>
<li>Copy 阶段：ReduceTask 从各个 MapTask 上远程拷贝一片数据，并针对某一片数据，如果其大小超过一定阈值，则写到磁盘上，否则直接放到内存中。</li>
<li>Sort 阶段：在远程拷贝数据的同时，ReduceTask 启动了两个后台线程对内存和磁盘上的文件进行合并，以防止内存使用过多或磁盘上文件过多。按照 MapReduce 语义，用户编写 reduce ()函数输入数据是按 key 进行聚集的一组数据。为了将 key 相同的数据聚在一起，Hadoop 采用了基于排序的策略。由于各个 MapTask 已经实现对自己的处理结果进行了局部排序，因此，ReduceTask 只需对所有数据进行一次归并排序即可。</li>
<li>Reduce 阶段：reduce ()函数将计算结果写到 HDFS 上。</li>
</ol>
<h4 id="ReduceTask-数量决定机制"><a href="#ReduceTask-数量决定机制" class="headerlink" title="ReduceTask 数量决定机制"></a>ReduceTask 数量决定机制</h4><p>设置 <strong>ReduceTask</strong> 并行度（个数），需要和 Partition 数量相同，不相同就为 1。</p>
<p>ReduceTask 的数量设置会导致资源数据倾斜的问题</p>
<h4 id="ReduceTask-源码解析流程"><a href="#ReduceTask-源码解析流程" class="headerlink" title="ReduceTask 源码解析流程"></a>ReduceTask 源码解析流程</h4><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202162640.png" alt="image.png"><br><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240202162650.png" alt="image.png"></p>
<h3 id="Join"><a href="#Join" class="headerlink" title="Join"></a>Join</h3><p>用于根据一个键值对两张表进行全连接</p>
<p><strong>注</strong>：最好是一张小表和一张大表，不建议在 ReduceTask 中用，最好在 Map 中用，Reduce 中数据量大，会拉低性能。</p>
<h4 id="示例-2"><a href="#示例-2" class="headerlink" title="示例"></a>示例</h4><p>Driver</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.mapjoin;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.net.URI;  </span><br><span class="line"><span class="keyword">import</span> java.net.URISyntaxException;  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MapJoinDriver</span> &#123;  </span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> IOException,  </span><br><span class="line">            URISyntaxException, ClassNotFoundException, InterruptedException &#123;  </span><br><span class="line"><span class="comment">// 1 获取 job信息  </span></span><br><span class="line">        <span class="type">Configuration</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Configuration</span>();  </span><br><span class="line">        <span class="type">Job</span> <span class="variable">job</span> <span class="operator">=</span> Job.getInstance(conf);  </span><br><span class="line"><span class="comment">// 2 设置加载 jar包路径  </span></span><br><span class="line">        job.setJarByClass(MapJoinDriver.class);  </span><br><span class="line"><span class="comment">// 3 关联 mapper        job.setMapperClass(MapJoinMapper.class);  </span></span><br><span class="line"><span class="comment">// 4 设置 Map输出 KV类型  </span></span><br><span class="line">        job.setMapOutputKeyClass(Text.class);  </span><br><span class="line">        job.setMapOutputValueClass(NullWritable.class);  </span><br><span class="line"><span class="comment">// 5 设置最终输出 KV类型  </span></span><br><span class="line">        job.setOutputKeyClass(Text.class);  </span><br><span class="line">        job.setOutputValueClass(NullWritable.class);  </span><br><span class="line"><span class="comment">// 加载缓存数据  </span></span><br><span class="line">        job.addCacheFile(<span class="keyword">new</span> <span class="title class_">URI</span>(<span class="string">&quot;file:///D:/input/tablecache/pd.txt&quot;</span>));  </span><br><span class="line"><span class="comment">// Map端 Join的逻辑不需要 Reduce阶段，设置 reduceTask数量为 0        job.setNumReduceTasks(0);  </span></span><br><span class="line"><span class="comment">// 6 设置输入输出路径  </span></span><br><span class="line">        FileInputFormat.setInputPaths(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/Users/mrli/work/bigdata/LearningFile/input/inputtable&quot;</span>));  </span><br><span class="line">        FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> <span class="title class_">Path</span>(<span class="string">&quot;/Users/mrli/work/bigdata/LearningFile/output/inputtable&quot;</span>));  </span><br><span class="line"><span class="comment">// 7 提交  </span></span><br><span class="line">        <span class="type">boolean</span> <span class="variable">b</span> <span class="operator">=</span> job.waitForCompletion(<span class="literal">true</span>);  </span><br><span class="line">        System.exit(b ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>Mapper</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">package</span> org.lch.mapreduce.mapjoin;  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">import</span> org.apache.commons.lang3.StringUtils;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FSDataInputStream;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.LongWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.NullWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> java.io.BufferedReader;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.io.InputStreamReader;  </span><br><span class="line"><span class="keyword">import</span> java.net.URI;  </span><br><span class="line"><span class="keyword">import</span> java.util.HashMap;  </span><br><span class="line"><span class="keyword">import</span> java.util.Map;  </span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">MapJoinMapper</span> <span class="keyword">extends</span> <span class="title class_">Mapper</span>&lt;LongWritable, Text, Text,  </span><br><span class="line">        NullWritable&gt; &#123;  </span><br><span class="line">    <span class="keyword">private</span> Map&lt;String, String&gt; pdMap = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;&gt;();  </span><br><span class="line">    <span class="keyword">private</span> <span class="type">Text</span> <span class="variable">text</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Text</span>();  </span><br><span class="line">    <span class="comment">//任务开始前将 pd数据缓存进 pdMap    @Override  </span></span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">setup</span><span class="params">(Context context)</span> <span class="keyword">throws</span> IOException,  </span><br><span class="line">            InterruptedException &#123;  </span><br><span class="line"><span class="comment">//通过缓存文件得到小表数据 pd.txt        URI[] cacheFiles = context.getCacheFiles();  </span></span><br><span class="line">        <span class="type">Path</span> <span class="variable">path</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Path</span>(cacheFiles[<span class="number">0</span>]);  </span><br><span class="line"><span class="comment">//获取文件系统对象,并开流  </span></span><br><span class="line">        <span class="type">FileSystem</span> <span class="variable">fs</span> <span class="operator">=</span> FileSystem.get(context.getConfiguration());  </span><br><span class="line">        <span class="type">FSDataInputStream</span> <span class="variable">fis</span> <span class="operator">=</span> fs.open(path);  </span><br><span class="line"><span class="comment">//通过包装流转换为 reader,方便按行读取  </span></span><br><span class="line">        <span class="type">BufferedReader</span> <span class="variable">reader</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">BufferedReader</span>(<span class="keyword">new</span>  </span><br><span class="line">                <span class="title class_">InputStreamReader</span>(fis, <span class="string">&quot;UTF-8&quot;</span>));  </span><br><span class="line">        <span class="comment">//逐行读取，按行处理  </span></span><br><span class="line">        String line;  </span><br><span class="line">        <span class="keyword">while</span> (StringUtils.isNotEmpty(line = reader.readLine())) &#123;  </span><br><span class="line"><span class="comment">//切割一行  </span></span><br><span class="line"><span class="comment">//01 小米  </span></span><br><span class="line">            String[] split = line.split(<span class="string">&quot;\t&quot;</span>);  </span><br><span class="line">            pdMap.put(split[<span class="number">0</span>], split[<span class="number">1</span>]);  </span><br><span class="line">        &#125;  </span><br><span class="line"><span class="comment">//关流  </span></span><br><span class="line">        IOUtils.closeStream(reader);  </span><br><span class="line">    &#125;  </span><br><span class="line">    <span class="meta">@Override</span>  </span><br><span class="line">    <span class="keyword">protected</span> <span class="keyword">void</span> <span class="title function_">map</span><span class="params">(LongWritable key, Text value, Context context)</span>  </span><br><span class="line">            <span class="keyword">throws</span> IOException, InterruptedException &#123;  </span><br><span class="line"><span class="comment">//读取大表数据  </span></span><br><span class="line"><span class="comment">//1001 01 1  </span></span><br><span class="line">        String[] fields = value.toString().split(<span class="string">&quot;\t&quot;</span>);  </span><br><span class="line"><span class="comment">//通过大表每行数据的 pid,去 pdMap里面取出 pname        String pname = pdMap.get(fields[1]);  </span></span><br><span class="line"><span class="comment">//将大表每行数据的 pid替换为 pname        text.set(fields[0] + &quot;\t&quot; + pname + &quot;\t&quot; + fields[2]);  </span></span><br><span class="line"><span class="comment">//写出  </span></span><br><span class="line">        context.write(text,NullWritable.get());  </span><br><span class="line">    &#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="MapReduce-调优"><a href="#MapReduce-调优" class="headerlink" title="MapReduce 调优"></a>MapReduce 调优</h1><p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240206193451.png" alt="image.png"></p>
<p><img src="https://raw.githubusercontent.com/MLiLay/img/main/img/20240206193510.png" alt="image.png"></p>
<h2 id="修改mapred-site-xml"><a href="#修改mapred-site-xml" class="headerlink" title="修改mapred-site.xml"></a>修改mapred-site.xml</h2><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">&lt;!-- 环形缓冲区大小，默认 100m --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>100<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 环形缓冲区溢写阈值，默认 0.8 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.sort.spill.percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.80<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- merge合并次数，默认10个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.io.sort.factor<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>10<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- maptask 内存，默认 1g； maptask 堆内存大小默认和该值大小一致</span></span><br><span class="line"><span class="comment">mapreduce.map.java.opts --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>The amount of memory to request from the</span><br><span class="line">scheduler for each map task. If this is not specified or is</span><br><span class="line">non-positive, it is inferred from mapreduce.map.java.opts and</span><br><span class="line">mapreduce.job.heap.memory-mb.ratio. If java-opts are also not</span><br><span class="line">specified, we set it to 1024.</span><br><span class="line"><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- matask的CPU核数，默认1个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- matask异常重试次数，默认4次 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.map.maxattempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 每个Reduce去Map中拉取数据的并行数。默认值是5 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.parallelcopies<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>5<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Buffer大小占Reduce可用内存的比例，默认值0.7 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.input.buffer.percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.70<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- Buffer中的数据达到多少比例开始写入磁盘，默认值0.66。 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.shuffle.merge.percent<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.66<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- reducetask 内存，默认 1g；reducetask 堆内存大小默认和该值大小一致</span></span><br><span class="line"><span class="comment">mapreduce.reduce.java.opts --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.memory.mb<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>-1<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">description</span>&gt;</span>The amount of memory to request from the</span><br><span class="line">scheduler for each reduce task. If this is not specified or</span><br><span class="line">is non-positive, it is inferred</span><br><span class="line">from mapreduce.reduce.java.opts and</span><br><span class="line">mapreduce.job.heap.memory-mb.ratio.</span><br><span class="line">If java-opts are also not specified, we set it to 1024.</span><br><span class="line"><span class="tag">&lt;/<span class="name">description</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- reducetask的 CPU核数，默认1个 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.cpu.vcores<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>2<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- reducetask失败重试次数，默认 4次 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.reduce.maxattempts<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>4<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 当MapTask完成的比例达到该值后才会为ReduceTask申请资源。默认是0.05</span></span><br><span class="line"><span class="comment">--&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.job.reduce.slowstart.completedmaps<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>0.05<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="comment">&lt;!-- 如果程序在规定的默认 10分钟内没有读到数据，将强制超时退出 --&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">name</span>&gt;</span>mapreduce.task.timeout<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">value</span>&gt;</span>600000<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h1 id="数据倾斜问题"><a href="#数据倾斜问题" class="headerlink" title="数据倾斜问题"></a>数据倾斜问题</h1><h2 id="数据倾斜现象"><a href="#数据倾斜现象" class="headerlink" title="数据倾斜现象"></a>数据倾斜现象</h2><p>数据频率倾斜——某一个区域的数据量要远远大于其他区域。</p>
<p>数据大小倾斜——部分记录的大小远远大于平均值。</p>
<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><ol>
<li>过滤空值</li>
<li>能在 <strong>map</strong> 阶段提前处理，最好先在 <strong>Map</strong> 阶段处理。如：<strong>Combiner</strong>、<strong>MapJoin</strong></li>
<li>设置多个 <strong>reduce</strong> 个数</li>
</ol>
</article><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/Hadoop/">Hadoop</a></div><div class="post_share"><div class="social-share" data-image="/img/avatar.JPG" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.3/sharejs/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2024/03/15/Hadoop-%E5%9F%BA%E7%A1%80-HDFS-NameNode%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/" title="Hadoop-HDFS-NameNode内存结构"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Hadoop-HDFS-NameNode内存结构</div></div></a></div><div class="next-post pull-right"><a href="/2024/03/14/Hadoop-%E5%B8%B8%E8%A7%81%E7%AB%AF%E5%8F%A3/" title="Hadoop-常用接口"><div class="cover" style="background: var(--default-bg-color)"></div><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">Hadoop-常用接口</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2024/01/28/Hadoop-%E5%9F%BA%E7%A1%80-HDFS-API/" title="Hadoop-HDFS-API"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-28</div><div class="title">Hadoop-HDFS-API</div></div></a></div><div><a href="/2024/03/21/Hadoop-%E5%9F%BA%E7%A1%80-HDFS-HDFS%E6%95%B0%E6%8D%AE%E8%AF%BB%E5%86%99/" title="Hadoop-HDFS-数据读写"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-21</div><div class="title">Hadoop-HDFS-数据读写</div></div></a></div><div><a href="/2024/03/15/Hadoop-%E5%9F%BA%E7%A1%80-HDFS-NameNode%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/" title="Hadoop-HDFS-NameNode内存结构"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-15</div><div class="title">Hadoop-HDFS-NameNode内存结构</div></div></a></div><div><a href="/2024/01/31/Hadoop-%E5%9F%BA%E7%A1%80-MapReduce-%E7%A4%BA%E4%BE%8B/" title="Hadoop-MapReduce-示例"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-01-31</div><div class="title">Hadoop-MapReduce-示例</div></div></a></div><div><a href="/2024/03/15/Hadoop-%E5%9F%BA%E7%A1%80-Yarn-%E5%8E%9F%E7%90%86%E5%8F%8A%E8%B0%83%E4%BC%98/" title="Hadoop-Yarn-原理及调优"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-15</div><div class="title">Hadoop-Yarn-原理及调优</div></div></a></div><div><a href="/2024/03/14/Hadoop-%E5%B8%B8%E8%A7%81%E7%AB%AF%E5%8F%A3/" title="Hadoop-常用接口"><div class="cover" style="background: var(--default-bg-color)"></div><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2024-03-14</div><div class="title">Hadoop-常用接口</div></div></a></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/avatar.JPG" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">CHLi</div><div class="author-info__description">Welcome to Mr.Li's blog</div></div><div class="card-info-data site-data is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">76</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">13</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">14</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/MLiLay"><i class="fab fa-github"></i><span>Follow Me</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">Welcome! This is MLiLay's Blog.</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%A1%86%E6%9E%B6"><span class="toc-number">1.</span> <span class="toc-text">框架</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Input-%E7%AB%AF"><span class="toc-number">2.</span> <span class="toc-text">Input 端</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#InputFormat"><span class="toc-number">2.1.</span> <span class="toc-text">InputFormat</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%88%87%E7%89%87%E4%B8%8E%E5%B9%B6%E8%A1%8C%E8%BF%90%E7%AE%97%E6%9C%BA%E5%88%B6"><span class="toc-number">2.1.1.</span> <span class="toc-text">切片与并行运算机制</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Job-%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E4%B8%8E%E5%88%87%E7%89%87%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3"><span class="toc-number">2.1.2.</span> <span class="toc-text">Job 提交任务与切片源码详解</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#Job-%E6%8F%90%E4%BA%A4%E4%BB%BB%E5%8A%A1%E6%BA%90%E7%A0%81"><span class="toc-number">2.1.2.1.</span> <span class="toc-text">Job 提交任务源码</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#FileInputFormat%E5%88%87%E7%89%87%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-number">2.1.3.</span> <span class="toc-text">FileInputFormat切片源码解析</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#TextInputFormat"><span class="toc-number">2.1.4.</span> <span class="toc-text">TextInputFormat</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#CombineTextInputFormat"><span class="toc-number">2.1.5.</span> <span class="toc-text">CombineTextInputFormat</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF"><span class="toc-number">2.1.5.1.</span> <span class="toc-text">应用场景</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E5%88%87%E7%89%87%E6%9C%80%E5%A4%A7%E5%80%BC%E8%AE%BE%E7%BD%AE"><span class="toc-number">2.1.5.2.</span> <span class="toc-text">虚拟存储切片最大值设置</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E5%88%87%E7%89%87%E6%9C%BA%E5%88%B6"><span class="toc-number">2.1.5.3.</span> <span class="toc-text">切片机制</span></a><ol class="toc-child"><li class="toc-item toc-level-5"><a class="toc-link" href="#%E8%99%9A%E6%8B%9F%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.5.3.1.</span> <span class="toc-text">虚拟存储过程</span></a></li><li class="toc-item toc-level-5"><a class="toc-link" href="#%E5%88%87%E7%89%87%E8%BF%87%E7%A8%8B"><span class="toc-number">2.1.5.3.2.</span> <span class="toc-text">切片过程</span></a></li></ol></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce-%E5%B7%A5%E4%BD%9C%E5%8E%9F%E7%90%86%EF%BC%88Shuffle%EF%BC%89"><span class="toc-number">3.</span> <span class="toc-text">MapReduce 工作原理（Shuffle）</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Input-Map-shuffle"><span class="toc-number">3.1.</span> <span class="toc-text">Input + Map + shuffle</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Reduce"><span class="toc-number">3.2.</span> <span class="toc-text">Reduce</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Shuffle-%E6%9C%BA%E5%88%B6%E8%AF%A6%E8%A7%A3"><span class="toc-number">3.3.</span> <span class="toc-text">Shuffle 机制详解</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Partition"><span class="toc-number">3.4.</span> <span class="toc-text">Partition</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E9%BB%98%E8%AE%A4%E5%88%86%E5%8C%BA"><span class="toc-number">3.4.1.</span> <span class="toc-text">默认分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%87%AA%E5%AE%9A%E4%B9%89%E5%88%86%E5%8C%BA"><span class="toc-number">3.4.2.</span> <span class="toc-text">自定义分区</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B"><span class="toc-number">3.4.3.</span> <span class="toc-text">示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#WritableComparable-%E8%87%AA%E5%AE%9A%E4%B9%89%E6%8E%92%E5%BA%8F%E9%A1%BA%E5%BA%8F"><span class="toc-number">3.5.</span> <span class="toc-text">WritableComparable (自定义排序顺序)</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B-1"><span class="toc-number">3.5.1.</span> <span class="toc-text">示例</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Combiner"><span class="toc-number">3.6.</span> <span class="toc-text">Combiner</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MapReduce-%E5%86%85%E6%A0%B8%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90"><span class="toc-number">3.7.</span> <span class="toc-text">MapReduce 内核源码解析</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#MapTask"><span class="toc-number">3.7.1.</span> <span class="toc-text">MapTask</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E6%B5%81%E7%A8%8B"><span class="toc-number">3.7.1.1.</span> <span class="toc-text">源码解析流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ReduceTask"><span class="toc-number">3.7.2.</span> <span class="toc-text">ReduceTask</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#ReduceTask-%E6%95%B0%E9%87%8F%E5%86%B3%E5%AE%9A%E6%9C%BA%E5%88%B6"><span class="toc-number">3.7.2.1.</span> <span class="toc-text">ReduceTask 数量决定机制</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#ReduceTask-%E6%BA%90%E7%A0%81%E8%A7%A3%E6%9E%90%E6%B5%81%E7%A8%8B"><span class="toc-number">3.7.2.2.</span> <span class="toc-text">ReduceTask 源码解析流程</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#Join"><span class="toc-number">3.7.3.</span> <span class="toc-text">Join</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E7%A4%BA%E4%BE%8B-2"><span class="toc-number">3.7.3.1.</span> <span class="toc-text">示例</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#MapReduce-%E8%B0%83%E4%BC%98"><span class="toc-number">4.</span> <span class="toc-text">MapReduce 调优</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E4%BF%AE%E6%94%B9mapred-site-xml"><span class="toc-number">4.1.</span> <span class="toc-text">修改mapred-site.xml</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E9%97%AE%E9%A2%98"><span class="toc-number">5.</span> <span class="toc-text">数据倾斜问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E5%80%BE%E6%96%9C%E7%8E%B0%E8%B1%A1"><span class="toc-number">5.1.</span> <span class="toc-text">数据倾斜现象</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95"><span class="toc-number">5.2.</span> <span class="toc-text">解决方法</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/11/Celeborn/" title="Celeborn">Celeborn</a><time datetime="2024-07-11T12:46:48.425Z" title="发表于 2024-07-11 20:46:48">2024-07-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/11/Spark-%E6%BA%90%E7%A0%81-Broadcast/" title="Spark-源码-Broadcast">Spark-源码-Broadcast</a><time datetime="2024-07-11T12:29:06.531Z" title="发表于 2024-07-11 20:29:06">2024-07-11</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/07/01/Spark-%E6%BA%90%E7%A0%81-%E4%BB%BB%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%B5%81%E7%A8%8B/" title="Spark-源码-任务提交流程（Yarn）">Spark-源码-任务提交流程（Yarn）</a><time datetime="2024-07-01T13:56:32.213Z" title="发表于 2024-07-01 21:56:32">2024-07-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/18/NIO%E4%B8%8E%E9%9B%B6%E6%8B%B7%E8%B4%9D/" title="NIO-NIO与零拷贝">NIO-NIO与零拷贝</a><time datetime="2024-05-18T06:57:04.000Z" title="发表于 2024-05-18 14:57:04">2024-05-18</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2024/05/18/NIO%EF%BC%88%E8%81%8A%E5%A4%A9%E6%A8%A1%E5%9E%8B%EF%BC%89/" title="NIO-聊天模型">NIO-聊天模型</a><time datetime="2024-05-18T06:32:05.000Z" title="发表于 2024-05-18 14:32:05">2024-05-18</time></div></div></div></div></div></div></main><footer id="footer"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2024 By CHLi</div><div class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly</a></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=4.13.0"></script><script src="/js/main.js?v=4.13.0"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0.33/dist/fancybox/fancybox.umd.min.js"></script><div class="js-pjax"><script>if (!window.MathJax) {
  window.MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']],
      tags: 'ams'
    },
    chtml: {
      scale: 1.1
    },
    options: {
      renderActions: {
        findScript: [10, doc => {
          for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
            const display = !!node.type.match(/; *mode=display/)
            const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display)
            const text = document.createTextNode('')
            node.parentNode.replaceChild(text, node)
            math.start = {node: text, delim: '', n: 0}
            math.end = {node: text, delim: '', n: 0}
            doc.math.push(math)
          }
        }, '']
      }
    }
  }
  
  const script = document.createElement('script')
  script.src = 'https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.min.js'
  script.id = 'MathJax-script'
  script.async = true
  document.head.appendChild(script)
} else {
  MathJax.startup.document.state(0)
  MathJax.texReset()
  MathJax.typesetPromise()
}</script></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div></body></html>